def @main(%input: Tensor[(1, 128, 128, 3), uint8] /* ty=Tensor[(1, 128, 128, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_prequant__143.input:0:0 */) -> Tensor[(1, 1001), uint8] {
  %0 = transpose(%input, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 3, 128, 128), uint8] span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_prequant__143:0:0 */;
  %1 = qnn.dequantize(%0, 0.0078125f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_prequant__143_DequantizeLinear__416.scale__33:0:0 */, 128 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_prequant__143_DequantizeLinear__416:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 3, 128, 128), float32] span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_prequant__143_DequantizeLinear__416:0:0 */;
  %2 = qnn.dequantize(meta[relay.Constant][0] /* ty=Tensor[(8, 3, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_0/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_0/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.00888241f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__139:0:0 */, 157 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_0/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(8, 3, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_0/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %3 = qnn.dequantize(meta[relay.Constant][1] /* ty=Tensor[(8), int32] span=MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_Fold_bias:0:0 */, 6.93938e-05f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_Fold_bias_dequant.scale__141:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(8), float32] span=MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_Fold_bias_dequant:0:0 */;
  %4 = expand_dims(%3, axis=1, num_newaxis=2) /* ty=Tensor[(8, 1, 1), float32] */;
  %5 = nn.conv2d(%1, %2, strides=[2, 2], padding=[0, 0, 1, 1], channels=8, kernel_size=[3, 3]) /* ty=Tensor[(1, 8, 64, 64), float32] span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_prequant:0:0 */;
  %6 = expand_dims(%4, axis=0) /* ty=Tensor[(1, 8, 1, 1), float32] */;
  %7 = add(%5, %6) /* ty=Tensor[(1, 8, 64, 64), float32] */;
  %8 = qnn.quantize(%7, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 8, 64, 64), uint8] span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize:0:0 */;
  %9 = qnn.dequantize(%8, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6_prequant__150_DequantizeLinear__450:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 8, 64, 64), float32] span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6_prequant__150_DequantizeLinear__450:0:0 */;
  %10 = qnn.dequantize(meta[relay.Constant][2] /* ty=Tensor[(8, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_1_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0894003f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__103:0:0 */, 204 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(8, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %11 = qnn.dequantize(meta[relay.Constant][3] /* ty=Tensor[(8), int32] span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_Fold_bias:0:0 */, 0.00210345f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_Fold_bias_dequant.scale__105:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(8), float32] span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %12 = expand_dims(%11, axis=1, num_newaxis=2) /* ty=Tensor[(8, 1, 1), float32] */;
  %13 = nn.conv2d(%9, %10, padding=[1, 1, 1, 1], groups=8, channels=8, kernel_size=[3, 3]) /* ty=Tensor[(1, 8, 64, 64), float32] span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6_prequant:0:0 */;
  %14 = expand_dims(%12, axis=0) /* ty=Tensor[(1, 8, 1, 1), float32] */;
  %15 = add(%13, %14) /* ty=Tensor[(1, 8, 64, 64), float32] */;
  %16 = qnn.quantize(%15, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 8, 64, 64), uint8] span=MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6_quantize:0:0 */;
  %17 = qnn.dequantize(%16, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Relu6_prequant__159_DequantizeLinear__442:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 8, 64, 64), float32] span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Relu6_prequant__159_DequantizeLinear__442:0:0 */;
  %18 = qnn.dequantize(meta[relay.Constant][4] /* ty=Tensor[(16, 8, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_1_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0160909f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__99:0:0 */, 120 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(16, 8, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %19 = qnn.dequantize(meta[relay.Constant][5] /* ty=Tensor[(16), int32] span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_Fold_bias:0:0 */, 0.000378595f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_Fold_bias_dequant.scale__101:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(16), float32] span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %20 = expand_dims(%19, axis=1, num_newaxis=2) /* ty=Tensor[(16, 1, 1), float32] */;
  %21 = nn.conv2d(%17, %18, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1]) /* ty=Tensor[(1, 16, 64, 64), float32] span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Relu6_prequant:0:0 */;
  %22 = expand_dims(%20, axis=0) /* ty=Tensor[(1, 16, 1, 1), float32] */;
  %23 = add(%21, %22) /* ty=Tensor[(1, 16, 64, 64), float32] */;
  %24 = qnn.quantize(%23, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 16, 64, 64), uint8] span=MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Relu6_quantize:0:0 */;
  %25 = qnn.dequantize(%24, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/Relu6_prequant__166_DequantizeLinear__429:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 16, 64, 64), float32] span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/Relu6_prequant__166_DequantizeLinear__429:0:0 */;
  %26 = qnn.dequantize(meta[relay.Constant][6] /* ty=Tensor[(16, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_2_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0479944f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__95:0:0 */, 204 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(16, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %27 = qnn.dequantize(meta[relay.Constant][7] /* ty=Tensor[(16), int32] span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_Fold_bias:0:0 */, 0.00112924f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_Fold_bias_dequant.scale__97:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(16), float32] span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %28 = expand_dims(%27, axis=1, num_newaxis=2) /* ty=Tensor[(16, 1, 1), float32] */;
  %29 = nn.conv2d(%25, %26, strides=[2, 2], padding=[0, 0, 1, 1], groups=16, channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 32, 32), float32] span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/Relu6_prequant:0:0 */;
  %30 = expand_dims(%28, axis=0) /* ty=Tensor[(1, 16, 1, 1), float32] */;
  %31 = add(%29, %30) /* ty=Tensor[(1, 16, 32, 32), float32] */;
  %32 = qnn.quantize(%31, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 16, 32, 32), uint8] span=MobilenetV1/MobilenetV1/Conv2d_2_depthwise/Relu6_quantize:0:0 */;
  %33 = qnn.dequantize(%32, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Relu6_prequant__175_DequantizeLinear__432:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 16, 32, 32), float32] span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Relu6_prequant__175_DequantizeLinear__432:0:0 */;
  %34 = qnn.dequantize(meta[relay.Constant][8] /* ty=Tensor[(32, 16, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_2_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0476783f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__91:0:0 */, 120 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(32, 16, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %35 = qnn.dequantize(meta[relay.Constant][9] /* ty=Tensor[(32), int32] span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_Fold_bias:0:0 */, 0.0011218f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_Fold_bias_dequant.scale__93:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(32), float32] span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %36 = expand_dims(%35, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %37 = nn.conv2d(%33, %34, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1]) /* ty=Tensor[(1, 32, 32, 32), float32] span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Relu6_prequant:0:0 */;
  %38 = expand_dims(%36, axis=0) /* ty=Tensor[(1, 32, 1, 1), float32] */;
  %39 = add(%37, %38) /* ty=Tensor[(1, 32, 32, 32), float32] */;
  %40 = qnn.quantize(%39, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 32, 32, 32), uint8] span=MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Relu6_quantize:0:0 */;
  %41 = qnn.dequantize(%40, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/Relu6_prequant__182_DequantizeLinear__441:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 32, 32, 32), float32] span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/Relu6_prequant__182_DequantizeLinear__441:0:0 */;
  %42 = qnn.dequantize(meta[relay.Constant][10] /* ty=Tensor[(32, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_3_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0340306f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__87:0:0 */, 149 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(32, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %43 = qnn.dequantize(meta[relay.Constant][11] /* ty=Tensor[(32), int32] span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_Fold_bias:0:0 */, 0.000800687f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_Fold_bias_dequant.scale__89:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(32), float32] span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %44 = expand_dims(%43, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %45 = nn.conv2d(%41, %42, padding=[1, 1, 1, 1], groups=32, channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 32, 32), float32] span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/Relu6_prequant:0:0 */;
  %46 = expand_dims(%44, axis=0) /* ty=Tensor[(1, 32, 1, 1), float32] */;
  %47 = add(%45, %46) /* ty=Tensor[(1, 32, 32, 32), float32] */;
  %48 = qnn.quantize(%47, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 32, 32, 32), uint8] span=MobilenetV1/MobilenetV1/Conv2d_3_depthwise/Relu6_quantize:0:0 */;
  %49 = qnn.dequantize(%48, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Relu6_prequant__191_DequantizeLinear__449:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 32, 32, 32), float32] span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Relu6_prequant__191_DequantizeLinear__449:0:0 */;
  %50 = qnn.dequantize(meta[relay.Constant][12] /* ty=Tensor[(32, 32, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_3_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0232934f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__83:0:0 */, 61 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(32, 32, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %51 = qnn.dequantize(meta[relay.Constant][13] /* ty=Tensor[(32), int32] span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_Fold_bias:0:0 */, 0.000548059f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_Fold_bias_dequant.scale__85:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(32), float32] span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %52 = expand_dims(%51, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %53 = nn.conv2d(%49, %50, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1]) /* ty=Tensor[(1, 32, 32, 32), float32] span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Relu6_prequant:0:0 */;
  %54 = expand_dims(%52, axis=0) /* ty=Tensor[(1, 32, 1, 1), float32] */;
  %55 = add(%53, %54) /* ty=Tensor[(1, 32, 32, 32), float32] */;
  %56 = qnn.quantize(%55, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 32, 32, 32), uint8] span=MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Relu6_quantize:0:0 */;
  %57 = qnn.dequantize(%56, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/Relu6_prequant__198_DequantizeLinear__435:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 32, 32, 32), float32] span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/Relu6_prequant__198_DequantizeLinear__435:0:0 */;
  %58 = qnn.dequantize(meta[relay.Constant][14] /* ty=Tensor[(32, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_4_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0122876f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__79:0:0 */, 122 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(32, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %59 = qnn.dequantize(meta[relay.Constant][15] /* ty=Tensor[(32), int32] span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_Fold_bias:0:0 */, 0.000289109f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_Fold_bias_dequant.scale__81:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(32), float32] span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %60 = expand_dims(%59, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %61 = nn.conv2d(%57, %58, strides=[2, 2], padding=[0, 0, 1, 1], groups=32, channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 16, 16), float32] span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/Relu6_prequant:0:0 */;
  %62 = expand_dims(%60, axis=0) /* ty=Tensor[(1, 32, 1, 1), float32] */;
  %63 = add(%61, %62) /* ty=Tensor[(1, 32, 16, 16), float32] */;
  %64 = qnn.quantize(%63, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 32, 16, 16), uint8] span=MobilenetV1/MobilenetV1/Conv2d_4_depthwise/Relu6_quantize:0:0 */;
  %65 = qnn.dequantize(%64, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Relu6_prequant__207_DequantizeLinear__440:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 32, 16, 16), float32] span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Relu6_prequant__207_DequantizeLinear__440:0:0 */;
  %66 = qnn.dequantize(meta[relay.Constant][16] /* ty=Tensor[(64, 32, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_4_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0120425f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__75:0:0 */, 148 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(64, 32, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %67 = qnn.dequantize(meta[relay.Constant][17] /* ty=Tensor[(64), int32] span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_Fold_bias:0:0 */, 0.000283341f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_Fold_bias_dequant.scale__77:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(64), float32] span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %68 = expand_dims(%67, axis=1, num_newaxis=2) /* ty=Tensor[(64, 1, 1), float32] */;
  %69 = nn.conv2d(%65, %66, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 16, 16), float32] span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Relu6_prequant:0:0 */;
  %70 = expand_dims(%68, axis=0) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %71 = add(%69, %70) /* ty=Tensor[(1, 64, 16, 16), float32] */;
  %72 = qnn.quantize(%71, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 64, 16, 16), uint8] span=MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Relu6_quantize:0:0 */;
  %73 = qnn.dequantize(%72, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/Relu6_prequant__214_DequantizeLinear__431:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 64, 16, 16), float32] span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/Relu6_prequant__214_DequantizeLinear__431:0:0 */;
  %74 = qnn.dequantize(meta[relay.Constant][18] /* ty=Tensor[(64, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_5_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0306289f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__71:0:0 */, 102 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(64, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %75 = qnn.dequantize(meta[relay.Constant][19] /* ty=Tensor[(64), int32] span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_Fold_bias:0:0 */, 0.000720652f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_Fold_bias_dequant.scale__73:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(64), float32] span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %76 = expand_dims(%75, axis=1, num_newaxis=2) /* ty=Tensor[(64, 1, 1), float32] */;
  %77 = nn.conv2d(%73, %74, padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 16, 16), float32] span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/Relu6_prequant:0:0 */;
  %78 = expand_dims(%76, axis=0) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %79 = add(%77, %78) /* ty=Tensor[(1, 64, 16, 16), float32] */;
  %80 = qnn.quantize(%79, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 64, 16, 16), uint8] span=MobilenetV1/MobilenetV1/Conv2d_5_depthwise/Relu6_quantize:0:0 */;
  %81 = qnn.dequantize(%80, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Relu6_prequant__223_DequantizeLinear__453:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 64, 16, 16), float32] span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Relu6_prequant__223_DequantizeLinear__453:0:0 */;
  %82 = qnn.dequantize(meta[relay.Constant][20] /* ty=Tensor[(64, 64, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_5_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0159395f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__67:0:0 */, 89 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(64, 64, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %83 = qnn.dequantize(meta[relay.Constant][21] /* ty=Tensor[(64), int32] span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_Fold_bias:0:0 */, 0.000375032f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_Fold_bias_dequant.scale__69:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(64), float32] span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %84 = expand_dims(%83, axis=1, num_newaxis=2) /* ty=Tensor[(64, 1, 1), float32] */;
  %85 = nn.conv2d(%81, %82, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 16, 16), float32] span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Relu6_prequant:0:0 */;
  %86 = expand_dims(%84, axis=0) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %87 = add(%85, %86) /* ty=Tensor[(1, 64, 16, 16), float32] */;
  %88 = qnn.quantize(%87, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 64, 16, 16), uint8] span=MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Relu6_quantize:0:0 */;
  %89 = qnn.dequantize(%88, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/Relu6_prequant__230_DequantizeLinear__438:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 64, 16, 16), float32] span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/Relu6_prequant__230_DequantizeLinear__438:0:0 */;
  %90 = qnn.dequantize(meta[relay.Constant][22] /* ty=Tensor[(64, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_6_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.00824124f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__63:0:0 */, 125 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(64, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %91 = qnn.dequantize(meta[relay.Constant][23] /* ty=Tensor[(64), int32] span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_Fold_bias:0:0 */, 0.000193904f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_Fold_bias_dequant.scale__65:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(64), float32] span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %92 = expand_dims(%91, axis=1, num_newaxis=2) /* ty=Tensor[(64, 1, 1), float32] */;
  %93 = nn.conv2d(%89, %90, strides=[2, 2], padding=[0, 0, 1, 1], groups=64, channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/Relu6_prequant:0:0 */;
  %94 = expand_dims(%92, axis=0) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %95 = add(%93, %94) /* ty=Tensor[(1, 64, 8, 8), float32] */;
  %96 = qnn.quantize(%95, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 64, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_6_depthwise/Relu6_quantize:0:0 */;
  %97 = qnn.dequantize(%96, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Relu6_prequant__239_DequantizeLinear__455:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 64, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Relu6_prequant__239_DequantizeLinear__455:0:0 */;
  %98 = qnn.dequantize(meta[relay.Constant][24] /* ty=Tensor[(128, 64, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_6_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0133386f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__59:0:0 */, 158 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 64, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %99 = qnn.dequantize(meta[relay.Constant][25] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_Fold_bias:0:0 */, 0.000313837f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_Fold_bias_dequant.scale__61:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %100 = expand_dims(%99, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %101 = nn.conv2d(%97, %98, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Relu6_prequant:0:0 */;
  %102 = expand_dims(%100, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %103 = add(%101, %102) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %104 = qnn.quantize(%103, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Relu6_quantize:0:0 */;
  %105 = qnn.dequantize(%104, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/Relu6_prequant__246_DequantizeLinear__430:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/Relu6_prequant__246_DequantizeLinear__430:0:0 */;
  %106 = qnn.dequantize(meta[relay.Constant][26] /* ty=Tensor[(128, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_7_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0291069f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__55:0:0 */, 122 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %107 = qnn.dequantize(meta[relay.Constant][27] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_Fold_bias:0:0 */, 0.000684841f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_Fold_bias_dequant.scale__57:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %108 = expand_dims(%107, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %109 = nn.conv2d(%105, %106, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/Relu6_prequant:0:0 */;
  %110 = expand_dims(%108, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %111 = add(%109, %110) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %112 = qnn.quantize(%111, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_7_depthwise/Relu6_quantize:0:0 */;
  %113 = qnn.dequantize(%112, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Relu6_prequant__255_DequantizeLinear__445:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Relu6_prequant__255_DequantizeLinear__445:0:0 */;
  %114 = qnn.dequantize(meta[relay.Constant][28] /* ty=Tensor[(128, 128, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_7_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.00714347f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__51:0:0 */, 134 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 128, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %115 = qnn.dequantize(meta[relay.Constant][29] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_Fold_bias:0:0 */, 0.000168075f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_Fold_bias_dequant.scale__53:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %116 = expand_dims(%115, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %117 = nn.conv2d(%113, %114, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Relu6_prequant:0:0 */;
  %118 = expand_dims(%116, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %119 = add(%117, %118) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %120 = qnn.quantize(%119, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Relu6_quantize:0:0 */;
  %121 = qnn.dequantize(%120, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/Relu6_prequant__262_DequantizeLinear__436:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/Relu6_prequant__262_DequantizeLinear__436:0:0 */;
  %122 = qnn.dequantize(meta[relay.Constant][30] /* ty=Tensor[(128, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_8_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.03095f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__47:0:0 */, 165 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %123 = qnn.dequantize(meta[relay.Constant][31] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_Fold_bias:0:0 */, 0.000728207f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_Fold_bias_dequant.scale__49:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %124 = expand_dims(%123, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %125 = nn.conv2d(%121, %122, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/Relu6_prequant:0:0 */;
  %126 = expand_dims(%124, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %127 = add(%125, %126) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %128 = qnn.quantize(%127, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_8_depthwise/Relu6_quantize:0:0 */;
  %129 = qnn.dequantize(%128, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Relu6_prequant__271_DequantizeLinear__443:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Relu6_prequant__271_DequantizeLinear__443:0:0 */;
  %130 = qnn.dequantize(meta[relay.Constant][32] /* ty=Tensor[(128, 128, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_8_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.00760898f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__43:0:0 */, 134 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 128, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %131 = qnn.dequantize(meta[relay.Constant][33] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_Fold_bias:0:0 */, 0.000179028f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_Fold_bias_dequant.scale__45:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %132 = expand_dims(%131, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %133 = nn.conv2d(%129, %130, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Relu6_prequant:0:0 */;
  %134 = expand_dims(%132, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %135 = add(%133, %134) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %136 = qnn.quantize(%135, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Relu6_quantize:0:0 */;
  %137 = qnn.dequantize(%136, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/Relu6_prequant__278_DequantizeLinear__454:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/Relu6_prequant__278_DequantizeLinear__454:0:0 */;
  %138 = qnn.dequantize(meta[relay.Constant][34] /* ty=Tensor[(128, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_9_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0212288f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__39:0:0 */, 120 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %139 = qnn.dequantize(meta[relay.Constant][35] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_Fold_bias:0:0 */, 0.000499482f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_Fold_bias_dequant.scale__41:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %140 = expand_dims(%139, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %141 = nn.conv2d(%137, %138, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/Relu6_prequant:0:0 */;
  %142 = expand_dims(%140, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %143 = add(%141, %142) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %144 = qnn.quantize(%143, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_9_depthwise/Relu6_quantize:0:0 */;
  %145 = qnn.dequantize(%144, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Relu6_prequant__287_DequantizeLinear__452:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Relu6_prequant__287_DequantizeLinear__452:0:0 */;
  %146 = qnn.dequantize(meta[relay.Constant][36] /* ty=Tensor[(128, 128, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_9_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0110914f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__35:0:0 */, 146 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 128, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %147 = qnn.dequantize(meta[relay.Constant][37] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_Fold_bias:0:0 */, 0.000260965f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_Fold_bias_dequant.scale__37:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %148 = expand_dims(%147, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %149 = nn.conv2d(%145, %146, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Relu6_prequant:0:0 */;
  %150 = expand_dims(%148, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %151 = add(%149, %150) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %152 = qnn.quantize(%151, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Relu6_quantize:0:0 */;
  %153 = qnn.dequantize(%152, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/Relu6_prequant__294_DequantizeLinear__446:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/Relu6_prequant__294_DequantizeLinear__446:0:0 */;
  %154 = qnn.dequantize(meta[relay.Constant][38] /* ty=Tensor[(128, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_10_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0227782f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__135:0:0 */, 135 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %155 = qnn.dequantize(meta[relay.Constant][39] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_Fold_bias:0:0 */, 0.000535936f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_Fold_bias_dequant.scale__137:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %156 = expand_dims(%155, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %157 = nn.conv2d(%153, %154, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/Relu6_prequant:0:0 */;
  %158 = expand_dims(%156, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %159 = add(%157, %158) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %160 = qnn.quantize(%159, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_10_depthwise/Relu6_quantize:0:0 */;
  %161 = qnn.dequantize(%160, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Relu6_prequant__303_DequantizeLinear__456:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Relu6_prequant__303_DequantizeLinear__456:0:0 */;
  %162 = qnn.dequantize(meta[relay.Constant][40] /* ty=Tensor[(128, 128, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_10_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.00722568f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__131:0:0 */, 131 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 128, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %163 = qnn.dequantize(meta[relay.Constant][41] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_Fold_bias:0:0 */, 0.000170009f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_Fold_bias_dequant.scale__133:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %164 = expand_dims(%163, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %165 = nn.conv2d(%161, %162, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Relu6_prequant:0:0 */;
  %166 = expand_dims(%164, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %167 = add(%165, %166) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %168 = qnn.quantize(%167, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Relu6_quantize:0:0 */;
  %169 = qnn.dequantize(%168, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/Relu6_prequant__310_DequantizeLinear__437:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/Relu6_prequant__310_DequantizeLinear__437:0:0 */;
  %170 = qnn.dequantize(meta[relay.Constant][42] /* ty=Tensor[(128, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_11_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.018258f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__127:0:0 */, 147 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %171 = qnn.dequantize(meta[relay.Constant][43] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_Fold_bias:0:0 */, 0.000429584f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_Fold_bias_dequant.scale__129:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %172 = expand_dims(%171, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %173 = nn.conv2d(%169, %170, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/Relu6_prequant:0:0 */;
  %174 = expand_dims(%172, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %175 = add(%173, %174) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %176 = qnn.quantize(%175, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_11_depthwise/Relu6_quantize:0:0 */;
  %177 = qnn.dequantize(%176, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Relu6_prequant__319_DequantizeLinear__448:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Relu6_prequant__319_DequantizeLinear__448:0:0 */;
  %178 = qnn.dequantize(meta[relay.Constant][44] /* ty=Tensor[(128, 128, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_11_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.00778962f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__123:0:0 */, 109 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 128, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %179 = qnn.dequantize(meta[relay.Constant][45] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_Fold_bias:0:0 */, 0.000183278f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_Fold_bias_dequant.scale__125:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %180 = expand_dims(%179, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %181 = nn.conv2d(%177, %178, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Relu6_prequant:0:0 */;
  %182 = expand_dims(%180, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %183 = add(%181, %182) /* ty=Tensor[(1, 128, 8, 8), float32] */;
  %184 = qnn.quantize(%183, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 8, 8), uint8] span=MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Relu6_quantize:0:0 */;
  %185 = qnn.dequantize(%184, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/Relu6_prequant__326_DequantizeLinear__433:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 8, 8), float32] span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/Relu6_prequant__326_DequantizeLinear__433:0:0 */;
  %186 = qnn.dequantize(meta[relay.Constant][46] /* ty=Tensor[(128, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_12_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.00576935f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__119:0:0 */, 125 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(128, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %187 = qnn.dequantize(meta[relay.Constant][47] /* ty=Tensor[(128), int32] span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_Fold_bias:0:0 */, 0.000135744f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_Fold_bias_dequant.scale__121:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %188 = expand_dims(%187, axis=1, num_newaxis=2) /* ty=Tensor[(128, 1, 1), float32] */;
  %189 = nn.conv2d(%185, %186, strides=[2, 2], padding=[0, 0, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 4, 4), float32] span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/Relu6_prequant:0:0 */;
  %190 = expand_dims(%188, axis=0) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %191 = add(%189, %190) /* ty=Tensor[(1, 128, 4, 4), float32] */;
  %192 = qnn.quantize(%191, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 128, 4, 4), uint8] span=MobilenetV1/MobilenetV1/Conv2d_12_depthwise/Relu6_quantize:0:0 */;
  %193 = qnn.dequantize(%192, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Relu6_prequant__335_DequantizeLinear__444:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 128, 4, 4), float32] span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Relu6_prequant__335_DequantizeLinear__444:0:0 */;
  %194 = qnn.dequantize(meta[relay.Constant][48] /* ty=Tensor[(256, 128, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_12_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.00996231f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__115:0:0 */, 113 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(256, 128, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %195 = qnn.dequantize(meta[relay.Constant][49] /* ty=Tensor[(256), int32] span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_Fold_bias:0:0 */, 0.000234398f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_Fold_bias_dequant.scale__117:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %196 = expand_dims(%195, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
  %197 = nn.conv2d(%193, %194, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 4, 4), float32] span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Relu6_prequant:0:0 */;
  %198 = expand_dims(%196, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %199 = add(%197, %198) /* ty=Tensor[(1, 256, 4, 4), float32] */;
  %200 = qnn.quantize(%199, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 256, 4, 4), uint8] span=MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Relu6_quantize:0:0 */;
  %201 = qnn.dequantize(%200, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/Relu6_prequant__342_DequantizeLinear__447:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 256, 4, 4), float32] span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/Relu6_prequant__342_DequantizeLinear__447:0:0 */;
  %202 = qnn.dequantize(meta[relay.Constant][50] /* ty=Tensor[(256, 1, 3, 3), uint8] span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_13_depthwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0257901f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__111:0:0 */, 165 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(256, 1, 3, 3), float32] span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %203 = qnn.dequantize(meta[relay.Constant][51] /* ty=Tensor[(256), int32] span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_Fold_bias:0:0 */, 0.000606801f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_Fold_bias_dequant.scale__113:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_Fold_bias_dequant:0:0 */;
  %204 = expand_dims(%203, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
  %205 = nn.conv2d(%201, %202, padding=[1, 1, 1, 1], groups=256, channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 4, 4), float32] span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/Relu6_prequant:0:0 */;
  %206 = expand_dims(%204, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %207 = add(%205, %206) /* ty=Tensor[(1, 256, 4, 4), float32] */;
  %208 = qnn.quantize(%207, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 256, 4, 4), uint8] span=MobilenetV1/MobilenetV1/Conv2d_13_depthwise/Relu6_quantize:0:0 */;
  %209 = qnn.dequantize(%208, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Relu6_prequant__351_DequantizeLinear__434:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 256, 4, 4), float32] span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Relu6_prequant__351_DequantizeLinear__434:0:0 */;
  %210 = qnn.dequantize(meta[relay.Constant][52] /* ty=Tensor[(256, 256, 1, 1), uint8] span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/MobilenetV1/Conv2d_13_pointwise/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.0233835f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__107:0:0 */, 144 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(256, 256, 1, 1), float32] span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %211 = qnn.dequantize(meta[relay.Constant][53] /* ty=Tensor[(256), int32] span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold_bias_dequant.MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold_bias:0:0 */, 0.000550179f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold_bias_dequant.scale__109:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold_bias_dequant:0:0 */;
  %212 = expand_dims(%211, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
  %213 = nn.conv2d(%209, %210, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 4, 4), float32] span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Relu6_prequant:0:0 */;
  %214 = expand_dims(%212, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %215 = add(%213, %214) /* ty=Tensor[(1, 256, 4, 4), float32] */;
  %216 = qnn.quantize(%215, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Relu6_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 256, 4, 4), uint8] span=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Relu6_quantize:0:0 */;
  %217 = qnn.dequantize(%216, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/Logits/AvgPool_1a/AvgPool_prequant__362_DequantizeLinear__451:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 256, 4, 4), float32] span=MobilenetV1/Logits/AvgPool_1a/AvgPool_prequant__362_DequantizeLinear__451:0:0 */;
  %218 = layout_transform(%217, src_layout="NCHW", dst_layout="NHWC") /* ty=Tensor[(1, 4, 4, 256), float32] */;
  %219 = nn.avg_pool2d(%218, pool_size=[4, 4], strides=[2, 2], padding=[0, 0, 0, 0], layout="NHWC", out_layout="NHWC") /* ty=Tensor[(1, 1, 1, 256), float32] span=MobilenetV1/Logits/AvgPool_1a/AvgPool_prequant:0:0 */;
  %220 = qnn.quantize(%219, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/Logits/AvgPool_1a/AvgPool_quantize:0:0 */, out_dtype="uint8", axis=3) /* ty=Tensor[(1, 1, 1, 256), uint8] span=MobilenetV1/Logits/AvgPool_1a/AvgPool_quantize:0:0 */;
  %221 = layout_transform(%220, src_layout="NHWC", dst_layout="NCHW") /* ty=Tensor[(1, 256, 1, 1), uint8] */;
  %222 = reshape(%221, newshape=[1, 256, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), uint8] span=MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_prequant__368:0:0 */;
  %223 = qnn.dequantize(%222, 0.0235285f /* ty=float32 span=MobilenetV1/MobilenetV1/Conv2d_0/Relu6_quantize.scale__301:0:0 */, 0 /* ty=int32 span=MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_prequant__368_DequantizeLinear__439:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 256, 1, 1), float32] span=MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_prequant__368_DequantizeLinear__439:0:0 */;
  %224 = qnn.dequantize(meta[relay.Constant][54] /* ty=Tensor[(1001, 256, 1, 1), uint8] span=MobilenetV1/Logits/Conv2d_1c_1x1/weights_quant/FakeQuantWithMinMaxVars_dequant.MobilenetV1/Logits/Conv2d_1c_1x1/weights_quant/FakeQuantWithMinMaxVars:0:0 */, 0.00554029f /* ty=float32 span=MobilenetV1/Logits/Conv2d_1c_1x1/weights_quant/FakeQuantWithMinMaxVars_dequant.scale__358:0:0 */, 94 /* ty=int32 span=MobilenetV1/Logits/Conv2d_1c_1x1/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1001, 256, 1, 1), float32] span=MobilenetV1/Logits/Conv2d_1c_1x1/weights_quant/FakeQuantWithMinMaxVars_dequant:0:0 */;
  %225 = qnn.dequantize(meta[relay.Constant][55] /* ty=Tensor[(1001), int32] span=MobilenetV1/Logits/Conv2d_1c_1x1/Conv2D_bias_dequant.MobilenetV1/Logits/Conv2d_1c_1x1/Conv2D_bias:0:0 */, 0.000130355f /* ty=float32 span=MobilenetV1/Logits/Conv2d_1c_1x1/Conv2D_bias_dequant.scale__360:0:0 */, 0 /* ty=int32 span=MobilenetV1/Logits/Conv2d_1c_1x1/Conv2D_bias_dequant:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1001), float32] span=MobilenetV1/Logits/Conv2d_1c_1x1/Conv2D_bias_dequant:0:0 */;
  %226 = expand_dims(%225, axis=1, num_newaxis=2) /* ty=Tensor[(1001, 1, 1), float32] */;
  %227 = nn.conv2d(%223, %224, padding=[0, 0, 0, 0], channels=1001, kernel_size=[1, 1]) /* ty=Tensor[(1, 1001, 1, 1), float32] span=MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_prequant:0:0 */;
  %228 = expand_dims(%226, axis=0) /* ty=Tensor[(1, 1001, 1, 1), float32] */;
  %229 = add(%227, %228) /* ty=Tensor[(1, 1001, 1, 1), float32] */;
  %230 = qnn.quantize(%229, 0.130833f /* ty=float32 span=MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_quantize.scale__378:0:0 */, 96 /* ty=int32 span=MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 1001, 1, 1), uint8] span=MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_quantize:0:0 */;
  %231 = reshape(%230, newshape=[1, 1001]) /* ty=Tensor[(1, 1001), uint8] span=MobilenetV1/Logits/SpatialSqueeze_prequant:0:0 */;
  %232 = qnn.dequantize(%231, 0.130833f /* ty=float32 span=MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_quantize.scale__378:0:0 */, 96 /* ty=int32 span=MobilenetV1/Logits/SpatialSqueeze_dequant:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 1001), float32] span=MobilenetV1/Logits/SpatialSqueeze_dequant:0:0 */;
  %233 = nn.softmax(%232, axis=1) /* ty=Tensor[(1, 1001), float32] span=MobilenetV1/Predictions/Reshape_1_prequant:0:0 */;
  qnn.quantize(%233, 0.00390625f /* ty=float32 span=MobilenetV1/Predictions/Reshape_1_quantize.scale__380:0:0 */, 0 /* ty=int32 span=MobilenetV1/Predictions/Reshape_1_quantize:0:0 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 1001), uint8] span=MobilenetV1/Predictions/Reshape_1_quantize:0:0 */
}

