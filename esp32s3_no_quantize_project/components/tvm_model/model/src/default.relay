def @main(%input_1: Tensor[(1, 32, 32, 3), float32] /* ty=Tensor[(1, 32, 32, 3), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1__31.input_1:0:0 */) -> Tensor[(1, 10), float32] {
  %0 = transpose(%input_1, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 3, 32, 32), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1__31:0:0 */;
  %1 = nn.conv2d(%0, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1.const_fold_opt__108:0:0 */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 32, 32), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */;
  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 32, 32), float32] */;
  %3 = nn.relu(%2) /* ty=Tensor[(1, 16, 32, 32), float32] span=Relu__5:0:0 */;
  %4 = nn.conv2d(%3, meta[relay.Constant][2] /* ty=Tensor[(16, 16, 3, 3), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1.const_fold_opt__119:0:0 */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 32, 32), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */;
  %5 = add(%4, meta[relay.Constant][3] /* ty=Tensor[(1, 16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 32, 32), float32] */;
  %6 = nn.relu(%5) /* ty=Tensor[(1, 16, 32, 32), float32] span=Relu__8:0:0 */;
  %7 = nn.conv2d(%6, meta[relay.Constant][4] /* ty=Tensor[(16, 16, 3, 3), float32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D.const_fold_opt__125:0:0 */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 32, 32), float32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */;
  %8 = add(%7, meta[relay.Constant][5] /* ty=Tensor[(1, 16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 32, 32), float32] */;
  %9 = add(%3, %8) /* ty=Tensor[(1, 16, 32, 32), float32] span=model/activation_2/Relu;model/add/add:0:0 */;
  %10 = nn.relu(%9) /* ty=Tensor[(1, 16, 32, 32), float32] span=Relu__12:0:0 */;
  %11 = nn.conv2d(%10, meta[relay.Constant][6] /* ty=Tensor[(32, 16, 1, 1), float32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1.const_fold_opt__112:0:0 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1]) /* ty=Tensor[(1, 32, 16, 16), float32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %12 = nn.conv2d(%10, meta[relay.Constant][8] /* ty=Tensor[(32, 16, 3, 3), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1.const_fold_opt__115:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 16, 16), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */;
  %13 = add(%12, meta[relay.Constant][9] /* ty=Tensor[(1, 32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 16, 16), float32] */;
  %14 = nn.relu(%13) /* ty=Tensor[(1, 32, 16, 16), float32] span=Relu__14:0:0 */;
  %15 = nn.conv2d(%14, meta[relay.Constant][10] /* ty=Tensor[(32, 32, 3, 3), float32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D.const_fold_opt__121:0:0 */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 16, 16), float32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */;
  %16 = add(%11, meta[relay.Constant][7] /* ty=Tensor[(1, 32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 16, 16), float32] */;
  %17 = add(%15, meta[relay.Constant][11] /* ty=Tensor[(1, 32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 16, 16), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(1, 32, 16, 16), float32] span=model/activation_4/Relu;model/add_1/add:0:0 */;
  %19 = nn.relu(%18) /* ty=Tensor[(1, 32, 16, 16), float32] span=Relu__19:0:0 */;
  %20 = nn.conv2d(%19, meta[relay.Constant][12] /* ty=Tensor[(64, 32, 1, 1), float32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1.const_fold_opt__117:0:0 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 8, 8), float32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %21 = nn.conv2d(%19, meta[relay.Constant][14] /* ty=Tensor[(64, 32, 3, 3), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1.const_fold_opt__120:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 8, 8), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */;
  %22 = add(%21, meta[relay.Constant][15] /* ty=Tensor[(1, 64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 8, 8), float32] */;
  %23 = nn.relu(%22) /* ty=Tensor[(1, 64, 8, 8), float32] span=Relu__21:0:0 */;
  %24 = nn.conv2d(%23, meta[relay.Constant][16] /* ty=Tensor[(64, 64, 3, 3), float32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D.const_fold_opt__123:0:0 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 8, 8), float32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */;
  %25 = add(%20, meta[relay.Constant][13] /* ty=Tensor[(1, 64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 8, 8), float32] */;
  %26 = add(%24, meta[relay.Constant][17] /* ty=Tensor[(1, 64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 8, 8), float32] */;
  %27 = add(%25, %26) /* ty=Tensor[(1, 64, 8, 8), float32] span=model/activation_6/Relu;model/add_2/add:0:0 */;
  %28 = nn.relu(%27) /* ty=Tensor[(1, 64, 8, 8), float32] span=Relu__26:0:0 */;
  %29 = layout_transform(%28, src_layout="NCHW", dst_layout="NHWC") /* ty=Tensor[(1, 8, 8, 64), float32] */;
  %30 = nn.avg_pool2d(%29, pool_size=[8, 8], strides=[8, 8], padding=[0, 0, 0, 0], layout="NHWC", out_layout="NHWC") /* ty=Tensor[(1, 1, 1, 64), float32] span=model/average_pooling2d/AvgPool:0:0 */;
  %31 = layout_transform(%30, src_layout="NHWC", dst_layout="NCHW") /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %32 = reshape(%31, newshape=[-1, 64]) /* ty=Tensor[(1, 64), float32] span=model/flatten/Reshape:0:0 */;
  %33 = nn.dense(%32, meta[relay.Constant][18] /* ty=Tensor[(10, 64), float32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, units=None, out_dtype="float32") /* ty=Tensor[(1, 10), float32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %34 = add(%33, meta[relay.Constant][19] /* ty=Tensor[(1, 10), float32] */) /* ty=Tensor[(1, 10), float32] span=Add__29:0:0 */;
  nn.softmax(%34, axis=1) /* ty=Tensor[(1, 10), float32] span=Identity:0:0 */
}

